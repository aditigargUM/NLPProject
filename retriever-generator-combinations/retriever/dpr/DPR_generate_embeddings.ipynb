{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"machine_shape":"hm","gpuType":"A100","authorship_tag":"ABX9TyP/cy2qAUqte3pHN/4TAU5c"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"gpuClass":"standard","accelerator":"GPU"},"cells":[{"cell_type":"markdown","source":["All the setup"],"metadata":{"id":"3881i1XJHXlU"}},{"cell_type":"code","source":["# This mounts your Google Drive to the Colab VM.\n","from google.colab import drive\n","drive.mount('/content/drive')\n","\n","# TODO: Enter the foldername in your Drive where you have saved the unzipped\n","# assignment folder, e.g. 'cs231n/assignments/assignment1/'\n","FOLDERNAME = 'MasterCourses/compsci685/Project'\n","assert FOLDERNAME is not None, \"[!] Enter the foldername.\"\n","\n","# Now that we've mounted your Drive, this ensures that\n","# the Python interpreter of the Colab VM can load\n","# python files from within it.\n","import sys\n","sys.path.append('/content/drive/My Drive/{}'.format(FOLDERNAME))\n","\n","%cd /content/drive/My\\ Drive/$FOLDERNAME/\n","!pip install transformers\n","!pip install faiss-cpu\n","\n","import torch\n","\n","# Confirm that the GPU is detected\n","\n","assert torch.cuda.is_available()\n","\n","# Get the GPU device name.\n","device_name = torch.cuda.get_device_name()\n","n_gpu = torch.cuda.device_count()\n","print(f\"Found device: {device_name}, n_gpu: {n_gpu}\")\n","\n","device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"i2AaXmGDt-J6","executionInfo":{"status":"ok","timestamp":1684093734323,"user_tz":240,"elapsed":10512,"user":{"displayName":"Aditi Garg","userId":"14692175669912421685"}},"outputId":"078d95c0-9fce-4066-d433-234c2a1ac285"},"execution_count":28,"outputs":[{"output_type":"stream","name":"stdout","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n","/content/drive/My Drive/MasterCourses/compsci685/Project\n","Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Requirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (4.29.1)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers) (3.12.0)\n","Requirement already satisfied: huggingface-hub<1.0,>=0.14.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.14.1)\n","Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (1.22.4)\n","Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (23.1)\n","Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0)\n","Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2022.10.31)\n","Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers) (2.27.1)\n","Requirement already satisfied: tokenizers!=0.11.3,<0.14,>=0.11.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.13.3)\n","Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers) (4.65.0)\n","Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.14.1->transformers) (2023.4.0)\n","Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.14.1->transformers) (4.5.0)\n","Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (1.26.15)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2022.12.7)\n","Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2.0.12)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.4)\n","Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Requirement already satisfied: faiss-cpu in /usr/local/lib/python3.10/dist-packages (1.7.4)\n","Found device: NVIDIA A100-SXM4-40GB, n_gpu: 1\n"]}]},{"cell_type":"markdown","source":["Initializing variables used throughout"],"metadata":{"id":"Mzk2mqpvHb1U"}},{"cell_type":"code","source":["import pickle\n","\n","with open(\"./dataset/passages\", \"rb\") as fp:   # Unpickling\n","      passages = pickle.load(fp)\n","\n","with open(\"./dataset/test_query_passages_answer_list\", \"rb\") as fp:   # Unpickling\n","        test_query_passages_answer_list = pickle.load(fp)\n","\n","test_queries = [test_query_passages_answer['query'] for test_query_passages_answer in test_query_passages_answer_list]"],"metadata":{"id":"u3zp-nPGHeRS","executionInfo":{"status":"ok","timestamp":1684093736041,"user_tz":240,"elapsed":1739,"user":{"displayName":"Aditi Garg","userId":"14692175669912421685"}}},"execution_count":29,"outputs":[]},{"cell_type":"markdown","source":["Obtain passage embeddings using model - facebook/dpr-ctx_encoder-multiset-base. Save once obtained and use the saved values. Comment out the code"],"metadata":{"id":"6owaF8DDIDkS"}},{"cell_type":"code","source":["from transformers import DPRContextEncoderTokenizerFast, DPRContextEncoder\n","\n","model_name = \"facebook/dpr-ctx_encoder-multiset-base\"\n","ctx_tokenizer = DPRContextEncoderTokenizerFast.from_pretrained(model_name)\n","ctx_encoder = DPRContextEncoder.from_pretrained(model_name).to(device)\n","\n","passages_embeddings = []\n","\n","for i in range(int(len(passages)/5)):\n","    print(i)\n","    model_input = ctx_tokenizer(passages[(5*i):(5*i+5)], truncation=True, padding=\"longest\", return_tensors=\"pt\")\n","    outputs=ctx_encoder(model_input[\"input_ids\"].to(device), return_dict=True)\n","    embs = outputs[\"pooler_output\"].detach().cpu().numpy()\n","    passages_embeddings.extend(embs)\n","\n","with open(\"retriever/dpr/embeddings/passages_embeddings_and_indexes/dpr-ctx_encoder-multiset-base/passages_embeddings\", \"wb\") as fp:   # Unpickling\n","    pickle.dump(passages_embeddings, fp)"],"metadata":{"id":"Nnxs1zNLs9mI"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Obtain test query embeddings using facebook/dpr-question_encoder-multiset-base"],"metadata":{"id":"BurxETFw7ebo"}},{"cell_type":"code","source":["from transformers import DPRQuestionEncoderTokenizerFast, DPRQuestionEncoder\n","\n","q_tokenizer = DPRQuestionEncoderTokenizerFast.from_pretrained(\"facebook/dpr-question_encoder-multiset-base\")\n","q_encoder = DPRQuestionEncoder.from_pretrained(\"facebook/dpr-question_encoder-multiset-base\").to(device)\n","\n","test_queries_embeddings = []\n","print(len(test_queries))\n","\n","for i in range(int(len(test_queries)/5)):\n","    print(i)\n","    model_input = q_tokenizer(test_queries[(5*i):(5*i+5)], truncation=True, padding=\"longest\", return_tensors=\"pt\")\n","    outputs=q_encoder(model_input[\"input_ids\"].to(device), return_dict=True)\n","    embs = outputs[\"pooler_output\"].detach().cpu().numpy()\n","    test_queries_embeddings.extend(embs)\n","\n","with open(\"retriever/dpr/embeddings/test_queries_embeddings/dpr-question_encoder-multiset-base/test_queries_embeddings\", \"wb\") as fp:   # Unpickling\n","    pickle.dump(test_queries_embeddings, fp)"],"metadata":{"id":"hNd-WV-38ChJ"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Build and save index"],"metadata":{"id":"9cBNurDX67t4"}},{"cell_type":"code","source":["import numpy as np\n","import faiss\n","\n","\n","def build_faiss_index(embeddings, filename):\n","  dim = 768\n","  m = 128\n","\n","  index = faiss.IndexFlatIP(dim)#, m, faiss.METRIC_INNER_PRODUCT)\n","  embeddings = np.stack(embeddings)\n","\n","  index.train(embeddings)\n","  index.add(embeddings)\n","\n","  faiss.write_index(index, filename)"],"metadata":{"id":"r_c_z7dmmgba","executionInfo":{"status":"ok","timestamp":1684093435059,"user_tz":240,"elapsed":392,"user":{"displayName":"Aditi Garg","userId":"14692175669912421685"}}},"execution_count":22,"outputs":[]},{"cell_type":"markdown","source":["Build passages faiss index for embeddings obtained from encoder - facebook/dpr-ctx_encoder-multiset-base"],"metadata":{"id":"UCwEUphbK4Nt"}},{"cell_type":"code","source":["build_faiss_index(passages_embeddings, \"retriever/dpr/embeddings/passages_embeddings_and_indexes/dpr-ctx_encoder-multiset-base/passages_faiss_index\")"],"metadata":{"id":"7uaW1sYonau7"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Trying another query encoder"],"metadata":{"id":"KqtjF5qf1Vpk"}},{"cell_type":"code","source":["!pip install -U sentence-transformers"],"metadata":{"id":"F-7vRs0W1tFC","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1684090138118,"user_tz":240,"elapsed":5259,"user":{"displayName":"Aditi Garg","userId":"14692175669912421685"}},"outputId":"fe92a7b1-7fc1-40ad-d425-c45ae6ec34c6"},"execution_count":4,"outputs":[{"output_type":"stream","name":"stdout","text":["Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Requirement already satisfied: sentence-transformers in /usr/local/lib/python3.10/dist-packages (2.2.2)\n","Requirement already satisfied: transformers<5.0.0,>=4.6.0 in /usr/local/lib/python3.10/dist-packages (from sentence-transformers) (4.29.1)\n","Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from sentence-transformers) (4.65.0)\n","Requirement already satisfied: torch>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from sentence-transformers) (2.0.0+cu118)\n","Requirement already satisfied: torchvision in /usr/local/lib/python3.10/dist-packages (from sentence-transformers) (0.15.1+cu118)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from sentence-transformers) (1.22.4)\n","Requirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (from sentence-transformers) (1.2.2)\n","Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from sentence-transformers) (1.10.1)\n","Requirement already satisfied: nltk in /usr/local/lib/python3.10/dist-packages (from sentence-transformers) (3.8.1)\n","Requirement already satisfied: sentencepiece in /usr/local/lib/python3.10/dist-packages (from sentence-transformers) (0.1.99)\n","Requirement already satisfied: huggingface-hub>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from sentence-transformers) (0.14.1)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.4.0->sentence-transformers) (3.12.0)\n","Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.4.0->sentence-transformers) (2023.4.0)\n","Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.4.0->sentence-transformers) (2.27.1)\n","Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.4.0->sentence-transformers) (6.0)\n","Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.4.0->sentence-transformers) (4.5.0)\n","Requirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.4.0->sentence-transformers) (23.1)\n","Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.6.0->sentence-transformers) (1.11.1)\n","Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.6.0->sentence-transformers) (3.1)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.6.0->sentence-transformers) (3.1.2)\n","Requirement already satisfied: triton==2.0.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.6.0->sentence-transformers) (2.0.0)\n","Requirement already satisfied: cmake in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch>=1.6.0->sentence-transformers) (3.25.2)\n","Requirement already satisfied: lit in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch>=1.6.0->sentence-transformers) (16.0.3)\n","Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers<5.0.0,>=4.6.0->sentence-transformers) (2022.10.31)\n","Requirement already satisfied: tokenizers!=0.11.3,<0.14,>=0.11.1 in /usr/local/lib/python3.10/dist-packages (from transformers<5.0.0,>=4.6.0->sentence-transformers) (0.13.3)\n","Requirement already satisfied: click in /usr/local/lib/python3.10/dist-packages (from nltk->sentence-transformers) (8.1.3)\n","Requirement already satisfied: joblib in /usr/local/lib/python3.10/dist-packages (from nltk->sentence-transformers) (1.2.0)\n","Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->sentence-transformers) (3.1.0)\n","Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.10/dist-packages (from torchvision->sentence-transformers) (8.4.0)\n","Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.6.0->sentence-transformers) (2.1.2)\n","Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.4.0->sentence-transformers) (1.26.15)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.4.0->sentence-transformers) (2022.12.7)\n","Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.4.0->sentence-transformers) (2.0.12)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.4.0->sentence-transformers) (3.4)\n","Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.6.0->sentence-transformers) (1.3.0)\n"]}]},{"cell_type":"code","source":["import pickle\n","\n","from sentence_transformers import SentenceTransformer\n","from transformers import AutoTokenizer\n","\n","model_name = \"sentence-transformers/msmarco-distilbert-base-tas-b\"\n","model = SentenceTransformer(model_name).to(device)\n","\n","test_queries_embeddings = []\n","\n","for i in range(int(len(test_queries)/5)):\n","    print(i)\n","    test_queries_embeddings.extend(model.encode(test_queries[(5*i):(5*i+5)]))\n","\n","with open(\"retriever/dpr/embeddings/test_queries_embeddings/msmarco-distilbert-base-tas-b/test_queries_embeddings\", \"wb\") as fp:   # Unpickling\n","    pickle.dump(test_queries_embeddings, fp)"],"metadata":{"id":"0W9hi_db1Xt2"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Using the model - sebastian-hofstaetter/distilbert-dot-tas_b-b256-msmarco to build embeddings"],"metadata":{"id":"2xKcHLNxjVsi"}},{"cell_type":"code","source":["from transformers import AutoTokenizer, AutoModel\n","\n","model_name = \"sebastian-hofstaetter/distilbert-dot-tas_b-b256-msmarco\"\n","tokenizer = AutoTokenizer.from_pretrained(model_name)\n","bert_model = AutoModel.from_pretrained(model_name).to(device)\n","\n","passages_embeddings = []\n","\n","for i in range(int(len(passages)/5)):\n","    print(i)\n","    model_input = tokenizer(passages[(5*i):(5*i+5)], truncation=True, padding=\"longest\", return_tensors=\"pt\")\n","    embs = bert_model(**model_input.to(device))[0][:,0,:].detach().cpu().numpy() # Gives us the cls token embeddings\n","    passages_embeddings.extend(embs)\n","\n","with open(\"retriever/dpr/embeddings/passages_embeddings_and_indexes/distilbert-dot-tas_b-b256-msmarco/passages_embeddings\", \"wb\") as fp:   # Unpickling\n","    pickle.dump(passages_embeddings, fp)"],"metadata":{"id":"sZqAMHHAjaqz"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["build_faiss_index(passages_embeddings, \"retriever/dpr/embeddings/passages_embeddings_and_indexes/distilbert-dot-tas_b-b256-msmarco/passages_faiss_index\")"],"metadata":{"id":"38jG-gDPnApE","executionInfo":{"status":"ok","timestamp":1684093560751,"user_tz":240,"elapsed":19703,"user":{"displayName":"Aditi Garg","userId":"14692175669912421685"}}},"execution_count":24,"outputs":[]},{"cell_type":"markdown","source":["Saving query embeddings using the same model"],"metadata":{"id":"YC4n_W2bzPw4"}},{"cell_type":"code","source":["from transformers import AutoTokenizer, AutoModel\n","\n","model_name = \"sebastian-hofstaetter/distilbert-dot-tas_b-b256-msmarco\"\n","tokenizer = AutoTokenizer.from_pretrained(model_name)\n","bert_model = AutoModel.from_pretrained(model_name).to(device)\n","\n","test_queries_embeddings = []\n","\n","for i in range(int(len(test_queries)/5)):\n","    print(i)\n","    model_input = tokenizer(test_queries[(5*i):(5*i+5)], truncation=True, padding=\"longest\", return_tensors=\"pt\")\n","    embs = bert_model(**model_input.to(device))[0][:,0,:].detach().cpu().numpy() # Gives us the cls token embeddings\n","    test_queries_embeddings.extend(embs)\n","\n","with open(\"retriever/dpr/embeddings/test_queries_embeddings/distilbert-dot-tas_b-b256-msmarco/test_queries_embeddings\", \"wb\") as fp:   # Unpickling\n","    pickle.dump(test_queries_embeddings, fp)"],"metadata":{"id":"kCD-eeCqzTL4"},"execution_count":null,"outputs":[]}]}